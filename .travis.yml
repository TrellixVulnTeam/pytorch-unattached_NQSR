# https://travis-ci.org/pytorch/pytorch
language: c

dist: xenial

git:
  submodules: false

sudo: true

env:
  global:
    - ECR_DOMAIN=308535385114.dkr.ecr.us-east-1.amazonaws.com
    - PYTORCH_IMAGE_TAG=226
    - CAFFE2_IMAGE_TAG=189
    - SCCACHE_BUCKET=ossci-compiler-cache

matrix:
    fast_finish: true
    include:
      - env: LINT_CHECK
        language: python
        python: "2.7"
        install: pip install flake8
        script: flake8
      - env: LINT_CHECK
        language: python
        python: "3.7"
        install: pip install flake8
        script: flake8
      - env: MYPY_TYPE_CHECK
        language: python
        python: "3.6"
        install: pip install mypy mypy-extensions
        script: mypy @mypy-files.txt

      # PyTorch CPU builds
      - name: "Docker: Trusty / py2.7.9"
        env: BUILD_ENVIRONMENT=pytorch-linux-trusty-py2.7.9
        resources:
          gpu: false
      - name: "Docker: Trusty / py2.7"
        env: BUILD_ENVIRONMENT=pytorch-linux-trusty-py2.7
        resources:
          gpu: false
      - name: "Docker: Trusty / py3.5"
        env: BUILD_ENVIRONMENT=pytorch-linux-trusty-py3.5
        resources:
          gpu: false
      - name: "Docker: Trusty / py3.6 / gcc4.8"
        env: BUILD_ENVIRONMENT=pytorch-linux-trusty-py3.6-gcc4.8
        resources:
          gpu: false
      - name: "Docker: Trusty / py3.6 / gcc5.4"
        env: BUILD_ENVIRONMENT=pytorch-linux-trusty-py3.6-gcc5.4
        resources:
          gpu: false
      - name: "Docker: Trusty / py3.6 / gcc7"
        env: BUILD_ENVIRONMENT=pytorch-linux-trusty-py3.6-gcc7
        resources:
          gpu: false
      - name: "Docker: Trusty / pynightly"
        env: BUILD_ENVIRONMENT=pytorch-linux-trusty-pynightly
        resources:
          gpu: false
      - name: "Docker: Xenial / py3.6 / clang5 / asan"
        env: BUILD_ENVIRONMENT=pytorch-linux-xenial-py3-clang5-asan
        resources:
          gpu: false

      # PyTorch CUDA builds
      - name: "Docker: Xenial / cuda8 / cudnn6 / py3"
        env:
          - BUILD_ENVIRONMENT=pytorch-linux-xenial-cuda8-cudnn6-py3
          - CUDA_VERSION=8
        resources:
          gpu: true
      - name: "Docker: Xenial / cuda9 / cudnn7 / py2"
        env:
          - BUILD_ENVIRONMENT=pytorch-linux-xenial-cuda9-cudnn7-py2
          - CUDA_VERSION=9
        resources:
          gpu: true
      - name: "Docker: Xenial / cuda9 / cudnn7 / py3"
        env:
          - BUILD_ENVIRONMENT=pytorch-linux-xenial-cuda9-cudnn7-py3
          - CUDA_VERSION=9
        resources:
          gpu: true
      - name: "Docker: Xenial / cuda9.2 / cudnn7 / py3 / gcc7"
        env:
          - BUILD_ENVIRONMENT=pytorch-linux-xenial-cuda9.2-cudnn7-py3-gcc7
          - CUDA_VERSION=9.2
        resources:
          gpu: true

      # We are not running macOS builds on Travis currently
      # - pytorch_macos_10_13_py3_build
      # - pytorch_macos_10_13_py3_test:
      #     requires:
      #       - pytorch_macos_10_13_py3_build
      # - pytorch_macos_10_13_cuda9_2_cudnn7_py3_build

      # - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build
      # - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_test:
      #     requires:
      #       - caffe2_py2_cuda8_0_cudnn6_ubuntu16_04_build
      # - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      # - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_test:
      #     requires:
      #       - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      # - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      # - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_test:
      #     requires:
      #       - caffe2_py2_cuda9_0_cudnn7_ubuntu16_04_build
      # - caffe2_py2_cuda9_0_cudnn7_aten_ubuntu16_04_build
      # - caffe2_py2_cuda9_0_cudnn7_aten_ubuntu16_04_test:
      #     requires:
      #       - caffe2_py2_cuda9_0_cudnn7_aten_ubuntu16_04_build
      # - caffe2_py2_mkl_ubuntu16_04_build
      # - caffe2_py2_mkl_ubuntu16_04_test:
      #     requires:
      #       - caffe2_py2_mkl_ubuntu16_04_build
      # - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build
      # - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_test:
      #     requires:
      #       - caffe2_py2_cuda9_1_cudnn7_ubuntu16_04_build
      # - caffe2_py2_gcc4_8_ubuntu14_04_build
      # - caffe2_py2_gcc4_8_ubuntu14_04_test:
      #     requires:
      #       - caffe2_py2_gcc4_8_ubuntu14_04_build
      # - caffe2_onnx_py2_gcc5_ubuntu16_04_build
      # - caffe2_onnx_py2_gcc5_ubuntu16_04_test:
      #     requires:
      #       - caffe2_onnx_py2_gcc5_ubuntu16_04_build
      # - caffe2_conda2_ubuntu16_04_build
      # - caffe2_conda2_ubuntu16_04_test:
      #     requires:
      #       - caffe2_conda2_ubuntu16_04_build
      # - caffe2_py2_cuda8_0_cudnn7_ubuntu16_04_build
      # - caffe2_py2_gcc4_9_ubuntu14_04_build
      # - caffe2_py2_clang3_8_ubuntu16_04_build
      # - caffe2_py2_clang3_9_ubuntu16_04_build
      # - caffe2_py2_gcc6_ubuntu16_04_build
      # - caffe2_py2_gcc7_ubuntu16_04_build
      # - caffe2_py2_cuda8_0_cudnn7_aten_ubuntu16_04_build
      # - caffe2_py2_android_ubuntu16_04_build
      # - caffe2_conda3_cuda9_0_cudnn7_ubuntu16_04_build
      # - caffe2_py2_cuda9_0_cudnn7_centos7_build

      # We are not running macOS builds on Travis currently
      # - caffe2_py2_ios_macos10_13_build
      # - caffe2_py2_system_macos10_13_build
      # - caffe2_conda2_macos10_13_build

      # We are not running macOS builds on Travis currently
      # - name: "Mac: 10.13 / py3"
      #   env: BUILD_ENVIRONMENT=pytorch-macos-10.13-py3
      #   os: osx
      #   install: skip
      #   script:
      #     - export DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer
      #     - ls /Applications
      #     - .jenkins/pytorch/macos-build.sh

install:
  - sudo pip install awscli
  - |
    if [ -n "${CUDA_VERSION}" ]; then
      curl -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
      echo "deb https://nvidia.github.io/libnvidia-container/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
      echo "deb https://nvidia.github.io/nvidia-container-runtime/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
      echo "deb https://nvidia.github.io/nvidia-docker/ubuntu14.04/amd64 /" | sudo tee -a /etc/apt/sources.list.d/nvidia-docker.list
    fi
  - sudo apt-get update
  - sudo apt-get install linux-headers-$(uname -r)
  - |
    if [ -n "${CUDA_VERSION}" ]; then
      wget 'https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-396.26.run'
      sudo /bin/bash ./NVIDIA-Linux-x86_64-396.26.run -s
      sudo apt-get install -y nvidia-docker2
    fi
  - sudo pkill -SIGHUP dockerd
  - |
    if [ -n "${CUDA_VERSION}" ]; then
      nvidia-smi
    fi
  - eval $(aws ecr get-login --region us-east-1 --no-include-email) # needs AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY envvars
  - echo "$ECR_DOMAIN/pytorch/$BUILD_ENVIRONMENT:$PYTORCH_IMAGE_TAG"
  - docker pull "$ECR_DOMAIN/pytorch/$BUILD_ENVIRONMENT:$PYTORCH_IMAGE_TAG"
script:
  - |
    if [ -n "${CUDA_VERSION}" ]; then
      id=$(docker run --runtime=nvidia -t -d -w /var/lib/jenkins "$ECR_DOMAIN/pytorch/$BUILD_ENVIRONMENT:$PYTORCH_IMAGE_TAG")
    else
      id=$(docker run -t -d -w /var/lib/jenkins "$ECR_DOMAIN/pytorch/$BUILD_ENVIRONMENT:$PYTORCH_IMAGE_TAG")
    fi
  - echo "declare -x SCCACHE_BUCKET=${SCCACHE_BUCKET}" > $TRAVIS_BUILD_DIR/env
  - # This IAM user allows write access to S3 bucket for sccache
  - echo "declare -x AWS_ACCESS_KEY_ID=AKIAI62M6LXUOP4I4UZA" >> $TRAVIS_BUILD_DIR/env
  - echo "declare -x AWS_SECRET_ACCESS_KEY=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" >> $TRAVIS_BUILD_DIR/env
  - echo "declare -x BUILD_ENVIRONMENT=${BUILD_ENVIRONMENT}" >> $TRAVIS_BUILD_DIR/env
  - echo "declare -x CUDA_VERSION=${CUDA_VERSION}" >> $TRAVIS_BUILD_DIR/env
  - export SCCACHE_MAX_JOBS=`expr $(nproc) - 1`
  - export MEMORY_LIMIT_MAX_JOBS=8  # cap # of parallel jobs at 8, to avoid OOM
  - export MAX_JOBS=$(( ${SCCACHE_MAX_JOBS} > ${MEMORY_LIMIT_MAX_JOBS} ? ${MEMORY_LIMIT_MAX_JOBS} : ${SCCACHE_MAX_JOBS} ))
  - echo "declare -x MAX_JOBS=${MAX_JOBS}" >> $TRAVIS_BUILD_DIR/env
  - echo "declare -x TORCH_CUDA_ARCH_LIST=6.0" >> $TRAVIS_BUILD_DIR/env
  - docker cp "$TRAVIS_BUILD_DIR/." "$id:/var/lib/jenkins/workspace"
  - (echo "source ./workspace/env" && echo 'sudo chown -R jenkins workspace && cd workspace && git submodule update --init && .jenkins/pytorch/build.sh && .jenkins/pytorch/test.sh') | docker exec -u jenkins -i "$id" bash
